:orphan:



.. _sphx_glr_auto_workshop:

.. _general_workshop:


Workshop at |CuttingEEG|
========================

In this hands-on session we will describe the philosophy, architecture and functionalities of NeuroPycon and provide illustrative examples through interactive notebooks.

We will show how to use NeuroPycon pipeline to analyze EEG (MEG) data with a focus on automatic artifact removal by ICA, ERP components computation and (if times allows) source reconstruction from MEG data.

Basic knowledge of (or a keen interest in) **Python** is required. Furthermore, we suggest the following lectures:

* |Gorgolewski| et al. (2011) Front. Neuroinform. 5:13
* |Gramfort| et al. (2013), Front. Neurosci. 7:267
* |Meunier_Pascarella| et al. (2020), Neuroimage 

.. |CuttingEEG| raw:: html

   <a href="https://cuttingeeg2021.org/" target="_blank">CuttingEEG</a>
   
.. |Gorgolewski| raw:: html

   <a href="https://www.frontiersin.org/articles/10.3389/fninf.2011.00013/full" target="_blank">Gorgolewski</a>

.. |Gramfort| raw:: html

   <a href="https://www.frontiersin.org/articles/10.3389/fnins.2013.00267/full" target="_blank">Gramfort</a>

.. |Meunier_Pascarella| raw:: html

   <a href="https://www.sciencedirect.com/science/article/pii/S1053811920305061" target="_blank">Meunier, Pascarella</a>

   

Installation
------------
We recommend to install neuropycon and the related software (MNE-python, Freesurfer) before the workshop. 

First, we recommend to install MNE python by following the |installation instructions|. The last version of MNE-python relies on python 3.9.

.. |installation instructions| raw:: html

   <a href="https://mne.tools/stable/install/index.html" target="_blank">MNE python installation instructions</a>
   

Alternativaly, you can create an enviroment by Anaconda and install the packages contained in :download:`requirements <https://github.com/neuropycon/ephypype/tree/master/doc/workshop/requirements.txt>` file, e.g.

.. code-block:: bash

        $ conda create -n cuttingeeg python=3.7
        $ pip install -r requirements.txt
        $ pip install jupyter


   
Install ephypype
^^^^^^^^^^^^^^^^
To install ephypype package, download from |github| the last version and install it:

.. code-block:: bash

        $ git clone https://github.com/neuropycon/ephypype.git
        $ cd ephypype
        $ python setup.py develop

.. |github| raw:: html

   <a href="https://github.com/neuropycon/ephypype" target="_blank">github</a>
   
   
Sample data
-----------
During the workshop we use some sample datasets that will be shared on |zenodo|


.. |zenodo| raw:: html

   <a href="https://zenodo.org/communities/cuttingeeg" target="_blank">zenodo</a>

Freesurfer
^^^^^^^^^^

1. Download Freesurfer software:

https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall

2. Follow the Installation instructions

https://surfer.nmr.mgh.harvard.edu/fswiki/LinuxInstall
   
   
Notebooks
---------
   
.. contents:: Contents
   :local:
   :depth: 3
    
    
    




.. raw:: html

    <div class="sphx-glr-clear"></div>



.. _sphx_glr_auto_workshop_eeg:

.. _erpcore:


ERP CORE dataset
^^^^^^^^^^^^^^^^

These examples demonstrate how to process 1 participant from the |ERP_CORE| dataset. It shows how to obtain N170 component from a face perception task by |NeuroPycon| pipelines.

.. |ERP_CORE| raw:: html
        
        <a href="https://erpinfo.org/erp-core" target="_blank">ERP CORE</a>

.. |NeuroPycon| raw:: html
        
        <a href="https://neuropycon.github.io/ephypype/index.html" target="_blank">NeuroPycon</a>



.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="02. Compute ERP">

.. only:: html

 .. figure:: /auto_workshop/eeg/images/thumb/sphx_glr_plot_ERP_thumb.png
     :alt: 02. Compute ERP

     :ref:`sphx_glr_auto_workshop_eeg_plot_ERP.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_workshop/eeg/plot_ERP

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="01. Preprocess EEG data">

.. only:: html

 .. figure:: /auto_workshop/eeg/images/thumb/sphx_glr_plot_eeg_preprocessing_thumb.png
     :alt: 01. Preprocess EEG data

     :ref:`sphx_glr_auto_workshop_eeg_plot_eeg_preprocessing.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_workshop/eeg/plot_eeg_preprocessing
.. raw:: html

    <div class="sphx-glr-clear"></div>



.. _sphx_glr_auto_workshop_meg:

.. _facedataset:


FACE dataset
^^^^^^^^^^^^

These examples demonstrate how to process 1 participant of the |FACE| dataset from |Wakeman_Henson|. The data consist of simultaneous MEG/EEG recordings
from 19 healthy participants performing a visual recognition task. Subjects were presented images of famous, unfamiliar and scrambled faces.
Each subject participated in 6 runs, each 7.5 min in duration.

.. |FACE| raw:: html
        
        <a href="https://openneuro.org/datasets/ds000117/versions/1.0.4" target="_blank">FACE</a>

.. |Wakeman_Henson| raw:: html
        
        <a href="https://www.nature.com/articles/sdata20151" target="_blank">Wakeman and Henson (2015)</a>

Here, we focus only on MEG data and use :func:`~ephypype.pipelines.create_pipeline_preproc_meeg` to preprocess the MEG raw data and :func:`~ephypype.pipelines.create_pipeline_source_reconstruction` to perform source reconstruction of time-locked event-related fields.



.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The solution of MEG inverse problem requires knowledge of the lead field matrix. A cortical seg...">

.. only:: html

 .. figure:: /auto_workshop/meg/images/thumb/sphx_glr_01-run-smri_reconall_thumb.png
     :alt: 01. Freesurfer anatomical pipeline

     :ref:`sphx_glr_auto_workshop_meg_01-run-smri_reconall.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_workshop/meg/01-run-smri_reconall

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="02. Preprocess MEG data">

.. only:: html

 .. figure:: /auto_workshop/meg/images/thumb/sphx_glr_02-plot_meg_preprocessing_thumb.png
     :alt: 02. Preprocess MEG data

     :ref:`sphx_glr_auto_workshop_meg_02-plot_meg_preprocessing.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_workshop/meg/02-plot_meg_preprocessing

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In the inv_solution_node the raw data are epoched accordingly to events specified in json file ...">

.. only:: html

 .. figure:: /auto_workshop/meg/images/thumb/sphx_glr_03-plot_events_inverse_stc_thumb.png
     :alt: 03. Compute inverse solution

     :ref:`sphx_glr_auto_workshop_meg_03-plot_events_inverse_stc.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_workshop/meg/03-plot_events_inverse_stc

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Group average of dSPM solutions obtained by plot_events_inverse for the contrast between both t...">

.. only:: html

 .. figure:: /auto_workshop/meg/images/thumb/sphx_glr_04-plot_stc_thumb.png
     :alt: 04. Plot contrast

     :ref:`sphx_glr_auto_workshop_meg_04-plot_stc.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /auto_workshop/meg/04-plot_stc
.. raw:: html

    <div class="sphx-glr-clear"></div>



.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-gallery


  .. container:: sphx-glr-download sphx-glr-download-python

    :download:`Download all examples in Python source code: auto_workshop_python.zip </auto_workshop/auto_workshop_python.zip>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

    :download:`Download all examples in Jupyter notebooks: auto_workshop_jupyter.zip </auto_workshop/auto_workshop_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
