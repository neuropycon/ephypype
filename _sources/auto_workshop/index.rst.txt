:orphan:


Workshop
========

In this hands-on session we will describe the philosophy, architecture and functionalities of NeuroPycon and provide illustrative examples through interactive notebooks.

We will show how to use NeuroPycon pipeline to analyze MEG data (:ref:`sphx_glr_auto_workshop_01_meg`) with a focus on automatic artifact removal by ICA and and source reconstruction.

In the past edition of |CuttingEEG| we showed how to use NeuroPycon pipeline to analyze EEG data (:ref:`sphx_glr_auto_workshop_02_eeg`) with a focus on automatic artifact removal by ICA and and ERP components computation.

Basic knowledge of (or a keen interest in) **Python** is required. Furthermore, we suggest the following lectures:

* |Gorgolewski| et al. (2011) Front. Neuroinform. 5:13
* |Gramfort| et al. (2013), Front. Neurosci. 7:267
* |Meunier_Pascarella| et al. (2020), Neuroimage 

.. |CuttingEEG| raw:: html

   <a href="https://cuttingeeg2021.org/" target="_blank">CuttingEEG</a>
   
.. |Gorgolewski| raw:: html

   <a href="https://www.frontiersin.org/articles/10.3389/fninf.2011.00013/full" target="_blank">Gorgolewski</a>

.. |Gramfort| raw:: html

   <a href="https://www.frontiersin.org/articles/10.3389/fnins.2013.00267/full" target="_blank">Gramfort</a>

.. |Meunier_Pascarella| raw:: html

   <a href="https://www.sciencedirect.com/science/article/pii/S1053811920305061" target="_blank">Meunier, Pascarella</a>




Installation
------------
We recommend to install neuropycon and the related software (MNE-python, Freesurfer) before the workshop. 

First, we recommend to install MNE python by following the |installation instructions|. The last version of MNE-python relies on python 3.10.

.. |installation instructions| raw:: html

   <a href="https://mne.tools/stable/install/index.html" target="_blank">MNE python installation instructions</a>
   

Alternativaly, you can create an enviroment by Anaconda or Mamba and install the packages contained in :download:`requirements <https://github.com/neuropycon/ephypype/tree/master/doc/workshop/01_meg/requirements.txt>` file, e.g.

.. code-block:: bash

        $ conda create -n practicalmeeg python=3.10
        $ pip install -r requirements.txt
        $ pip install jupyter


   
Install ephypype
^^^^^^^^^^^^^^^^

.. comment
    To install ephypype package, you can use the Pypi version

    .. code-block:: bash

            $ pip install ephypype==0.3.dev0

To install ephypype package, you can use the Pypi version 

.. code-block:: bash

        $ pip install ephypype

or alternatively, you can download from |github| the last version and install it:

.. code-block:: bash

        $ git clone https://github.com/neuropycon/ephypype.git
        $ cd ephypype
        $ python setup.py develop

.. |github| raw:: html

   <a href="https://github.com/neuropycon/ephypype" target="_blank">github</a>
   
   
Sample data
-----------
During the workshop we use some sample datasets that will be shared on |zenodo|


.. |zenodo| raw:: html

   <a href="https://doi.org/10.5281/zenodo.7424167" target="_blank">zenodo</a>

Freesurfer
^^^^^^^^^^

1. Download Freesurfer software:

https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall

2. Follow the Installation instructions

https://surfer.nmr.mgh.harvard.edu/fswiki/LinuxInstall
   


Notebooks
---------
   
.. contents:: Contents
   :local:
   :depth: 3
    
    
    





.. raw:: html

    <div class="sphx-glr-thumbnails">


.. raw:: html

    </div>




FACE dataset
^^^^^^^^^^^^

These examples demonstrate how to process 1 participant of the |FACE| dataset from |Wakeman_Henson|. The data consist of simultaneous MEG/EEG recordings
from 19 healthy participants performing a visual recognition task. Subjects were presented images of famous, unfamiliar and scrambled faces.
Each subject participated in 6 runs, each 7.5 min in duration.

.. |FACE| raw:: html
        
        <a href="https://openneuro.org/datasets/ds000117/versions/1.0.4" target="_blank">FACE</a>

.. |Wakeman_Henson| raw:: html
        
        <a href="https://www.nature.com/articles/sdata20151" target="_blank">Wakeman and
 Henson (2015)</a>

Here, we focus only on MEG data and use :func:`~ephypype.pipelines.create_pipeline_preproc_meeg` to preprocess the MEG raw data and :func:`~ephypype.pipelines.create_pipeline_source_reconstruction` to perform source reconstruction of time-locked event-related fields.



.. raw:: html

    <div class="sphx-glr-thumbnails">


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This workflow runs the `Nipype &lt;http://nipype.readthedocs.io/en/latest/#&gt;`_ Interface wrapping ...">

.. only:: html

  .. image:: /auto_workshop/01_meg/images/thumb/sphx_glr_01-run-smri_reconall_thumb.png
    :alt: 01. Freesurfer anatomical pipeline

  :ref:`sphx_glr_auto_workshop_01_meg_01-run-smri_reconall.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">01. Freesurfer anatomical pipeline</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="02. Preprocess MEG data">

.. only:: html

  .. image:: /auto_workshop/01_meg/images/thumb/sphx_glr_plot_01_meg_preprocessing_thumb.png
    :alt: 02. Preprocess MEG data

  :ref:`sphx_glr_auto_workshop_01_meg_plot_01_meg_preprocessing.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">02. Preprocess MEG data</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="The first node of the workflow (:ref:`concat_event`) **extracts the events** from stimulus chan...">

.. only:: html

  .. image:: /auto_workshop/01_meg/images/thumb/sphx_glr_plot_02_events_inverse_stc_thumb.png
    :alt: 03. Compute inverse solution

  :ref:`sphx_glr_auto_workshop_01_meg_plot_02_events_inverse_stc.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">03. Compute inverse solution</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Group average of dSPM solutions obtained by plot_events_inverse for the contrast between both t...">

.. only:: html

  .. image:: /auto_workshop/01_meg/images/thumb/sphx_glr_plot_03_stc_thumb.png
    :alt: 04. Plot contrast

  :ref:`sphx_glr_auto_workshop_01_meg_plot_03_stc.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">04. Plot contrast</div>
    </div>


.. raw:: html

    </div>




ERP CORE dataset
^^^^^^^^^^^^^^^^

These examples demonstrate how to process 1 participant from the |ERP_CORE| dataset. It shows how to obtain N170 component from a face perception task by |NeuroPycon| pipelines.

.. |ERP_CORE| raw:: html
        
        <a href="https://erpinfo.org/erp-core" target="_blank">ERP CORE</a>

.. |NeuroPycon| raw:: html
        
        <a href="https://neuropycon.github.io/ephypype/index.html" target="_blank">NeuroPycon</a>



.. raw:: html

    <div class="sphx-glr-thumbnails">


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="02. Compute ERP">

.. only:: html

  .. image:: /auto_workshop/02_eeg/images/thumb/sphx_glr_plot_ERP_thumb.png
    :alt: 02. Compute ERP

  :ref:`sphx_glr_auto_workshop_02_eeg_plot_ERP.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">02. Compute ERP</div>
    </div>


.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="01. Preprocess EEG data">

.. only:: html

  .. image:: /auto_workshop/02_eeg/images/thumb/sphx_glr_plot_eeg_preprocessing_thumb.png
    :alt: 01. Preprocess EEG data

  :ref:`sphx_glr_auto_workshop_02_eeg_plot_eeg_preprocessing.py`

.. raw:: html

      <div class="sphx-glr-thumbnail-title">01. Preprocess EEG data</div>
    </div>


.. raw:: html

    </div>


.. toctree::
   :hidden:
   :includehidden:

   /auto_workshop/01_meg/index.rst
   /auto_workshop/02_eeg/index.rst


.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-gallery

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download all examples in Python source code: auto_workshop_python.zip </auto_workshop/auto_workshop_python.zip>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download all examples in Jupyter notebooks: auto_workshop_jupyter.zip </auto_workshop/auto_workshop_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
