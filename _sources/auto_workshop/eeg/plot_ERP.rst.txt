
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_workshop/eeg/plot_ERP.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_workshop_eeg_plot_ERP.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_workshop_eeg_plot_ERP.py:


===============
02. Compute ERP
===============
This workflow mainly call the ephypype pipeline computing N170 component
from raw data specified by the user. The first Node of the workflow
(extract_events Node) extract the events from raw data. The events are saved
in the Node directory.
In the ERP_pipeline the raw data are epoched accordingly to events extracted in
extract_events Node.
The evoked datasets are created by averaging the different conditions specified
in json file. 

.. GENERATED FROM PYTHON SOURCE LINES 14-32

.. code-block:: default

    # Authors: Annalisa Pascarella <a.pascarella@iac.cnr.it>
    # License: BSD (3-clause)

    # sphinx_gallery_thumbnail_number = 1


    import os.path as op
    import json
    import pprint  # noqa
    import ephypype

    import nipype.pipeline.engine as pe
    from nipype.interfaces.utility import Function

    from ephypype.nodes import create_iterator, create_datagrabber
    from ephypype.pipelines.preproc_meeg import create_pipeline_evoked
    from ephypype.datasets import fetch_erpcore_dataset








.. GENERATED FROM PYTHON SOURCE LINES 33-34

Let us fetch the data first. It is around 90 MB download.

.. GENERATED FROM PYTHON SOURCE LINES 34-118

.. code-block:: default

    base_path = op.join(op.dirname(ephypype.__file__), '..', 'doc/workshop')
    data_path = fetch_erpcore_dataset(base_path)

    # Read experiment params as json
    params = json.load(open("params.json"))

    pprint.pprint({'parameters': params})
    print(params["general"])

    data_type = params["general"]["data_type"]
    subject_ids = params["general"]["subject_ids"]
    NJOBS = params["general"]["NJOBS"]
    session_ids = params["general"]["session_ids"]

    # ERP params
    ERP_str = 'ERP'
    pprint.pprint({'ERP': params[ERP_str]})
    events_id = params[ERP_str]['events_id']
    condition = params[ERP_str]['condition']
    baseline = tuple(params[ERP_str]['baseline'])
    events_file = params[ERP_str]['events_file']
    t_min = params[ERP_str]['tmin']
    t_max = params[ERP_str]['tmax']


    def get_events(raw_ica, subject):
        '''
        The events are extracted from annotation. The events are saved
        to the Node directory.
        We take the ica file from the
        preprocessing workflow directory, i.e. the cleaned raw data.
        '''
        print(subject, raw_ica)
        import mne
        import numpy as np

        rename_events = {
            '201': 'response/correct',
            '202': 'response/error'
        }
    
        for i in range(1, 180+1):
            orig_name = f'{i}'
        
            if 1 <= i <= 40:
                new_name = 'stimulus/face/normal'
            elif 41 <= i <= 80:
                new_name = 'stimulus/car/normal'
            elif 101 <= i <= 140:
                new_name = 'stimulus/face/scrambled'
            elif 141 <= i <= 180:
                new_name = 'stimulus/car/scrambled'
            else:
                continue

            rename_events[orig_name] = new_name

        raw = mne.io.read_raw_fif(raw_ica, preload=True)
        events_from_annot, event_dict  = mne.events_from_annotations(raw)
    
        faces = list()
        car = list()
        for key in event_dict.keys():
    
            if rename_events[key] == 'stimulus/car/normal':
                car.append(event_dict[key])
            elif rename_events[key] == 'stimulus/face/normal':
                faces.append(event_dict[key])
        print(faces)
        print(car)
        merged_events = mne.merge_events(events_from_annot, faces, 1)
        merged_events = mne.merge_events(merged_events, car, 2)
        print(events_from_annot[:10])
        print(merged_events[:10])
        print(np.sum(merged_events[:,2]==1))
        print(np.sum(merged_events[:,2]==2))
        

        event_file = raw_ica.replace('.fif', '-eve.fif')
        mne.write_events(event_file, merged_events)

        return event_file
    





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    {'parameters': {'ERP': {'baseline': [None, 0],
                            'condition': ['faces', 'car'],
                            'events_file': '*_filt_ica-eve.fif',
                            'events_id': {'car': 2, 'faces': 1},
                            'tmax': 0.8,
                            'tmin': -0.2},
                    'general': {'NJOBS': 2,
                                'data_path': '/media/pasca/pasca_media/eeg/cuttingeeg/ERP_CORE',
                                'data_type': 'eeg',
                                'session_ids': ['N170'],
                                'subject_ids': ['016']},
                    'preprocessing': {'EoG_ch_name': ['HEOG', 'VEOG'],
                                      'bipolar': {'HEOG': ['HEOG_left',
                                                           'HEOG_right'],
                                                  'VEOG': ['VEOG_lower', 'Fp2']},
                                      'ch_new_names': {'FP1': 'Fp1', 'FP2': 'Fp2'},
                                      'down_sfreq': 256,
                                      'h_freq': 150,
                                      'l_freq': 0.1,
                                      'montage': 'standard_1005',
                                      'n_components': 28,
                                      'reject': {'eeg': 0.00035, 'eog': 0.0005}}}}
    {'NJOBS': 2, 'subject_ids': ['016'], 'session_ids': ['N170'], 'data_path': '/media/pasca/pasca_media/eeg/cuttingeeg/ERP_CORE', 'data_type': 'eeg'}
    {'ERP': {'baseline': [None, 0],
             'condition': ['faces', 'car'],
             'events_file': '*_filt_ica-eve.fif',
             'events_id': {'car': 2, 'faces': 1},
             'tmax': 0.8,
             'tmin': -0.2}}




.. GENERATED FROM PYTHON SOURCE LINES 119-123

Defining pipeline to compute inverse solution
##############################################################################
 Then, we create our workflow and specify the `base_dir` which tells
 nipype the directory in which to store the outputs.

.. GENERATED FROM PYTHON SOURCE LINES 123-163

.. code-block:: default



    # workflow directory within the `base_dir`
    ERP_pipeline_name = ERP_str + '_workflow'

    main_workflow = pe.Workflow(name=ERP_pipeline_name)
    main_workflow.base_dir = data_path

    # We create a node to pass input filenames to DataGrabber from nipype
    infosource = create_iterator(['subject_id', 'session_id'],
                                 [subject_ids, session_ids])

    # and a node to grab data. The template_args in this node iterate upon
    # the values in the infosource node
    ica_dir = op.join(
            data_path, 'preprocessing_workflow', 'preproc_eeg_pipeline')


    template_path = "_session_id_%s_subject_id_%s/ica/sub-%s_ses-%s_*filt_ica.fif"
    template_args = [['session_id', 'subject_id', 'subject_id', 'session_id']]
    datasource = create_datagrabber(ica_dir, template_path, template_args)


    # We connect the output of infosource node to the one of datasource.
    # So, these two nodes taken together can grab data.
    main_workflow.connect(infosource, 'subject_id', datasource,  'subject_id')
    main_workflow.connect(infosource, 'session_id', datasource, 'session_id')

    # We define the Node that encapsulates run_events_concatenate function
    extract_events = pe.Node(
        Function(input_names=['raw_ica', 'subject'],
                 output_names=['event_file'],
                 function=get_events),
        name='extract_events')

    main_workflow.connect(datasource, 'raw_file',
                          extract_events, 'raw_ica')
    main_workflow.connect(infosource, 'subject_id',
                          extract_events, 'subject')








.. GENERATED FROM PYTHON SOURCE LINES 164-166

Ephypype creates for us a pipeline to compute evoked data which can be
connected to these nodes we created.

.. GENERATED FROM PYTHON SOURCE LINES 166-178

.. code-block:: default

    ERP_workflow = create_pipeline_evoked(
            data_path, data_type=data_type, pipeline_name="ERP_pipeline",
            events_id=events_id, baseline=baseline,
            condition=condition, t_min=t_min, t_max=t_max)

    main_workflow.connect(infosource, 'subject_id',
                          ERP_workflow, 'inputnode.sbj_id')
    main_workflow.connect(datasource, 'raw_file',
                          ERP_workflow, 'inputnode.raw')
    main_workflow.connect(extract_events, 'event_file',
                          ERP_workflow, 'inputnode.events_file')








.. GENERATED FROM PYTHON SOURCE LINES 179-180

To do so, we first write the workflow graph (optional)

.. GENERATED FROM PYTHON SOURCE LINES 180-186

.. code-block:: default

    main_workflow.write_graph(graph2use='colored')  # colored

    # Finally, we are now ready to execute our workflow.
    main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}
    # Run workflow locally on 1 CPU
    main_workflow.run(plugin='LegacyMultiProc', plugin_args={'n_procs': NJOBS})




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    <networkx.classes.digraph.DiGraph object at 0x7efc7e334e10>




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  8.424 seconds)


.. _sphx_glr_download_auto_workshop_eeg_plot_ERP.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_ERP.py <plot_ERP.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_ERP.ipynb <plot_ERP.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
