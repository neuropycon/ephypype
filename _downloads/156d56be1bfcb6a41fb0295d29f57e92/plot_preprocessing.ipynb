{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Preprocess MEG data\nThe preprocessing pipeline runs the ICA algorithm for an\nautomatic removal of eyes and heart related artefacts.\nA report is automatically generated and can be used to correct\nand/or fine-tune the correction in each subject.\n\nThe **input** data can be in **ds** or **fif** format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Annalisa Pascarella <a.pascarella@iac.cnr.it>\n#          Mainak Jas <mainakjas@gmail.com>\n# License: BSD (3-clause)\n\n# sphinx_gallery_thumbnail_number = 2\n\nimport os.path as op\n\nimport nipype.pipeline.engine as pe\n\nimport ephypype\nfrom ephypype.nodes import create_iterator, create_datagrabber\nfrom ephypype.datasets import fetch_omega_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us fetch the data first. It is around 675 MB download.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_path = op.join(op.dirname(ephypype.__file__), '..', 'examples')\ndata_path = fetch_omega_dataset(base_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "then read the parameters for experiment and preprocessing from a\n:download:`json <https://github.com/neuropycon/ephypype/tree/master/examples/params.json>`\nfile and print it\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json  # noqa\nimport pprint  # noqa\nparams = json.load(open(\"params.json\"))\n\npprint.pprint({'experiment parameters': params[\"general\"]})\nsubject_ids = params[\"general\"][\"subject_ids\"]  # sub-003\nsession_ids = params[\"general\"][\"session_ids\"]  # ses-0001\nNJOBS = params[\"general\"][\"NJOBS\"]\ndata_type = params[\"general\"][\"data_type\"]\n\npprint.pprint({'preprocessing parameters': params[\"preprocessing\"]})\ndown_sfreq = params[\"preprocessing\"]['down_sfreq']\nl_freq = params[\"preprocessing\"]['l_freq']\nh_freq = params[\"preprocessing\"]['h_freq']\nECG_ch_name = params[\"preprocessing\"]['ECG_ch_name']\nEoG_ch_name = params[\"preprocessing\"]['EoG_ch_name']\nvariance = params[\"preprocessing\"]['variance']\nreject = params[\"preprocessing\"]['reject']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\npreproc_pipeline_name = 'preprocessing_workflow'\n\nmain_workflow = pe.Workflow(name=preproc_pipeline_name)\nmain_workflow.base_dir = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "infosource = create_iterator(['subject_id', 'session_id'],\n                             [subject_ids, session_ids])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_path = '*%s/%s/meg/%s*rest*0_60*raw.fif'\ntemplate_args = [['subject_id', 'session_id', 'subject_id']]\ndatasource = create_datagrabber(data_path, template_path, template_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ephypype creates for us a pipeline which can be connected to these\nnodes we created. The preprocessing pipeline is implemented by the function\n:func:`ephypype.pipelines.preproc_meeg.create_pipeline_preproc_meeg`, thus to\ninstantiate this pipeline node, we import it and pass our\nparameters to it.\nThe preprocessing pipeline contains two nodes that are based on the MNE\nPython functions performing the decomposition of the MEG/EEG signal using an\n|ICA| algorithm.\n\n.. |ICA| raw:: html\n\n   <a href=\"https://mne.tools/stable/auto_tutorials/preprocessing/plot_40_artifact_correction_ica.html\" target=\"_blank\">ICA</a>\n\nIn particular, the two nodes are:\n\n* :class:`ephypype.interfaces.mne.preproc.PreprocFif` performs filtering on the raw data\n* :class:`ephypype.interfaces.mne.preproc.CompIca` computes ICA solution on raw fif data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ephypype.pipelines import create_pipeline_preproc_meeg  # noqa\npreproc_workflow = create_pipeline_preproc_meeg(\n    data_path, l_freq=l_freq, h_freq=h_freq, down_sfreq=down_sfreq,\n    variance=variance, ECG_ch_name=ECG_ch_name, EoG_ch_name=EoG_ch_name,\n    data_type=data_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. First, we connect the two outputs\n(subject_id and session_id) of the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id', datasource, 'subject_id')\nmain_workflow.connect(infosource, 'session_id', datasource, 'session_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, for the inputnode of the preproc_workflow. Things will become\nclearer in a moment when we plot the graph of the workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id',\n                      preproc_workflow, 'inputnode.subject_id')\nmain_workflow.connect(datasource, 'raw_file',\n                      preproc_workflow, 'inputnode.raw_file')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do so, we first write the workflow graph (optional)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.write_graph(graph2use='colored')  # colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and visualize it. Take a moment to pause and notice how the connections\nhere correspond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  # noqa\nimg = plt.imread(op.join(data_path, preproc_pipeline_name, 'graph.png'))\nplt.figure(figsize=(6, 6))\nplt.imshow(img)\nplt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\n\n# Run workflow locally on 1 CPU\nmain_workflow.run(plugin='MultiProc', plugin_args={'n_procs': NJOBS})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The output is the preprocessed data stored in the workflow directory\ndefined by `base_dir`.\n\nIt\u2019s a good rule to inspect the report file saved in the same dir to look at\nthe excluded ICA components. It is also possible to include and exclude more\ncomponents by using either a jupyter notebook or the preprocessing pipeline\nwith different flag parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import mne  # noqa\nfrom ephypype.gather import get_results  # noqa\n\nica_files, raw_files = get_results(main_workflow.base_dir,\n                                   main_workflow.name, pipeline='ica')\n\nfor ica_file, raw_file in zip(ica_files, raw_files):\n    raw = mne.io.read_raw_fif(raw_file)\n    ica = mne.preprocessing.read_ica(ica_file)\n    ica.plot_properties(raw, picks=ica.exclude, figsize=[4.5, 4.5])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}