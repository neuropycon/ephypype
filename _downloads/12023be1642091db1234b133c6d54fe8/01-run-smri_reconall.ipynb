{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# 01. Freesurfer anatomical pipeline\n\nThis workflow runs the [Nipype](http://nipype.readthedocs.io/en/latest/#)\nInterface wrapping the [recon-all](https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all)\ncommand of Freesurfer.\n\nThe solution of MEG inverse problem requires knowledge of the lead field\nmatrix. A cortical segmentation of the anatomical MRI is necessary to generate\nthe source space, where the neural activity will be estimated.\nA [Boundary Element Model](https://mne.tools/stable/auto_tutorials/forward/30_forward.html?highlight=bem)\n(BEM) which uses the segmented surfaces is used to\nconstruct the lead field matrix. To perform the cortical segmentation we\nprovide a workflow based on nipype Interface wrapping the\n[recon-all](https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all) command of\nFreesurfer. The output of `reconallnode` node is used as input of another node that\ncreates the BEM surfaces using the FreeSurfer watershed algorithm.\n\nThe workflow generates an HTML report displaying the BEM surfaces as\ncolored contours overlaid on the T1 MRI images to verify that the surfaces do not intersect.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Make sure that Freesurfer is properly configured before\n    running this script.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Annalisa Pascarella <a.pascarella@iac.cnr.it>\n# License: BSD (3-clause)\n\n# sphinx_gallery_thumbnail_number = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import modules\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport json\nimport pprint\nimport os.path as op\nimport nipype.pipeline.engine as pe\n\nfrom nipype.interfaces.freesurfer import ReconAll\nfrom nipype.interfaces.utility import Function\n\nfrom ephypype.nodes import create_iterator, create_datagrabber\nfrom ephypype.compute_fwd_problem import _create_bem_sol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define data and variables\nLet us specify the variables that are specific for the data analysis (the\nmain directories where the data are stored, the list of subjects and\nsessions, ...) and the variable specific for the particular pipeline\n(MRI path, Freesurfer fir, ...) in a |params.json| file\n\n.. |params.json| replace::\n  :download:`json <https://github.com/neuropycon/ephypype/tree/master/doc/workshop/01_meg/params.json>`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Read experiment params as json\nparams = json.load(open(\"params.json\"))\npprint.pprint({'parameters': params[\"general\"]})\n\nsubjects_dir = params[\"general\"][\"subjects_dir\"]\nsubject_ids = params[\"general\"][\"subject_ids\"]\nNJOBS = params[\"general\"][\"NJOBS\"]\n\nif \"subjects_dir\" in params[\"general\"].keys():\n    data_path = params[\"general\"][\"subjects_dir\"]\nelse:\n    data_path = os.path.expanduser(\"~\")\n\n# Check envoiroment variables\nif not os.environ.get('FREESURFER_HOME'):\n    raise RuntimeError('FREESURFER_HOME environment variable not set')\nos.environ[\"SUBJECTS_DIR\"] = subjects_dir\nprint(f'SUBJECTS_DIR {os.environ[\"SUBJECTS_DIR\"]} ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify Nodes\nInfosource and Datasource\n\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\nWe create a node to pass input filenames and a node to grab data. The\n``template_args`` in this ``datasource`` node iterate upon\nthe values in the ``infosource`` node.\nHere we define an input field for ``create_datagrabber`` called\n``subject_id``. This is then used to set the template (see %s in the\ntemplate). We look for .nii files located in the ``ses-mri/anat`` folder of\nthe subject\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "infosource = create_iterator(['subject_id'], [subject_ids])\n\ntemplate_path = '../%s/ses-mri/anat/%s*T1w.nii.gz'\ntemplate_args = [['subject_id', 'subject_id']]\ninfields = ['subject_id']\ndatasource = create_datagrabber(data_path, template_path, template_args,\n                                infields=infields)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### ReconAll Node\n``recon_all`` node calls the nipype Interface wrapping the recon-all function\nof Freesurfer that generates surfaces and parcellations of structural\ndata from anatomical images of a subject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recon_all = pe.Node(interface=ReconAll(), infields=['T1_files'],\n                    name='recon_all')\nrecon_all.inputs.subjects_dir = subjects_dir\nrecon_all.inputs.directive = 'all'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n### BEM Node\nWe define a node wrapping an ephypype function calling\n[make_watershed_bem](https://mne.tools/stable/generated/mne.bem.make_watershed_bem.html?highlight=make_watershed_bem#mne.bem.make_watershed_bem)\nof MNE Python package for BEM generation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bem_generation = pe.Node(interface=Function(\n    input_names=['subjects_dir', 'sbj_id'], output_names=['sbj_id'],\n    function=_create_bem_sol), name='call_mne_watershed_bem')\nbem_generation.inputs.subjects_dir = subjects_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Create workflows\nFirst, we create a workflow containing the `reconallnode` ans specify the\nconnections between all nodes (``infosource``, ``datasource`` and\n``recon_all``)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# reconall_workflow will be a node of the main workflow\nreconall_workflow_name = 'segmentation_workflow'\nreconall_workflow = pe.Workflow(name=reconall_workflow_name)\nreconall_workflow.base_dir = data_path\n\nreconall_workflow.connect(infosource, 'subject_id', datasource,  'subject_id')\nreconall_workflow.connect(infosource, 'subject_id', recon_all, 'subject_id')\nreconall_workflow.connect(datasource, 'raw_file', recon_all, 'T1_files')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create the main workflow where we will connect the output of\n``reconall_workflow`` to the input of ``bem_generation`` node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "freesurfer_workflow_name = 'FS_workflow'\nmain_workflow = pe.Workflow(name=freesurfer_workflow_name)\nmain_workflow.base_dir = subjects_dir\n\n\nmain_workflow.connect(reconall_workflow, 'recon_all.subject_id',\n                      bem_generation, 'sbj_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run workflow\nExecute the pipeline\nThe code above sets up all the necessary data structures and the connectivity\nbetween the processes, but does not generate any output. To actually run the\nanalysis on the data the :func:`~nipype.pipeline.engine.Pipeline.Run`\nfunction needs to be called.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.write_graph(graph2use='colored')\nmain_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\nmain_workflow.run(plugin='LegacyMultiProc', plugin_args={'n_procs': NJOBS})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\nThe output of this workflow is the cortical segmentation of the\nstructural data that we find in the ``subjects_dir`` and will be used in\n`plot_events_inverse`\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The main advantage to use this workflow lies in the parallel\n      processing provided by nipype engine, that allows segmenting the 19 MRI\n      data in less than two days while processing a single MRI generally\n      takes one day.</p></div>\n<img src=\"file://../../img/graph_FS.png\" width=\"50%\" align=\"center\">\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}