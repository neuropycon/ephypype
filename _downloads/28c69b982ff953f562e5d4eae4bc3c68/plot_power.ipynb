{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Compute PSD on sensor space\nThe power pipeline computes the power spectral density (PSD)\non epochs or raw data on **sensor space** or **source space**.\nThe **mean PSD** for each selected frequency band is also\ncomputed and saved in a numpy file.\n\nThe input data shoud be in **fif** or **numpy** format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Annalisa Pascarella <a.pascarella@iac.cnr.it>\n#          Mainak Jas <mainakjas@gmail.com>\n# License: BSD (3-clause)\n\n# sphinx_gallery_thumbnail_number = 2\n\nimport os.path as op\nimport numpy as np\nimport nipype.pipeline.engine as pe\n\nimport ephypype\nfrom ephypype.nodes import create_iterator, create_datagrabber\nfrom ephypype.datasets import fetch_omega_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us fetch the data first. It is around 675 MB download.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_path = op.join(op.dirname(ephypype.__file__), '..', 'examples')\ndata_path = fetch_omega_dataset(base_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "then read the parameters for experiment and power analysis from a\n:download:`json <https://github.com/neuropycon/ephypype/tree/master/examples/params.json>`\nfile and print it\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json  # noqa\nimport pprint  # noqa\nparams = json.load(open(\"params.json\"))\n\npprint.pprint({'experiment parameters': params[\"general\"]})\nsubject_ids = params[\"general\"][\"subject_ids\"]  # sub-003\nsession_ids = params[\"general\"][\"session_ids\"]  # ses-0001\nNJOBS = params[\"general\"][\"NJOBS\"]\n\npprint.pprint({'power parameters': params[\"power\"]})\nfreq_band_names = params[\"power\"]['freq_band_names']\nfreq_bands = params[\"power\"]['freq_bands']\nis_epoched = params[\"power\"]['is_epoched']\nfmin = params[\"power\"]['fmin']\nfmax = params[\"power\"]['fmax']\npower_method = params[\"power\"]['method']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we create our workflow and specify the `base_dir` which tells\nnipype the directory in which to store the outputs.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# workflow directory within the `base_dir`\npower_analysis_name = 'power_workflow'\n\nmain_workflow = pe.Workflow(name=power_analysis_name)\nmain_workflow.base_dir = data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a node to pass input filenames to DataGrabber from nipype\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "infosource = create_iterator(['subject_id', 'session_id'],\n                             [subject_ids, session_ids])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and a node to grab data. The template_args in this node iterate upon\nthe values in the infosource node\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "template_path = '*%s/%s/meg/%s*rest*0_60*ica.fif'\ntemplate_args = [['subject_id', 'session_id', 'subject_id']]\ndatasource = create_datagrabber(data_path, template_path, template_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ephypype creates for us a pipeline which can be connected to these\nnodes we created. The power pipeline in the **sensor space** is implemented\nby the function :func:`ephypype.pipelines.power.create_pipeline_power`, thus\nto instantiate this pipeline node, we import it and pass our parameters\nto it.\nThe power pipeline contains only one node\n:class:`ephypype.interfaces.mne.power.Power`\nthat wraps the MNE-Python functions :func:`mne.time_frequency.psd_welch` and\n:func:`mne.time_frequency.psd_multitaper` for computing the PSD using\nWelch's method and multitapers respectively.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ephypype.pipelines import create_pipeline_power  # noqa\npower_workflow = create_pipeline_power(data_path, freq_bands,\n                                       fmin=fmin, fmax=fmax,\n                                       method=power_method,\n                                       is_epoched=is_epoched)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then connect the nodes two at a time. First, we connect the two outputs\n(subject_id and session_id) of the infosource node to the datasource node.\nSo, these two nodes taken together can grab data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(infosource, 'subject_id', datasource, 'subject_id')\nmain_workflow.connect(infosource, 'session_id', datasource, 'session_id')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, for the inputnode of the power_workflow. Things will become\nclearer in a moment when we plot the graph of the workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.connect(datasource, 'raw_file',\n                      power_workflow, 'inputnode.fif_file')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To do so, we first write the workflow graph (optional)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.write_graph(graph2use='colored')  # colored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and visualize it. Take a moment to pause and notice how the connections\nhere correspond to how we connected the nodes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt  # noqa\nimg = plt.imread(op.join(data_path, power_analysis_name, 'graph.png'))\nplt.figure(figsize=(6, 6))\nplt.imshow(img)\nplt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are now ready to execute our workflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "main_workflow.config['execution'] = {'remove_unnecessary_outputs': 'false'}\n\n# Run workflow locally on 1 CPU\nmain_workflow.run(plugin='MultiProc', plugin_args={'n_procs': NJOBS})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The outputs are the **psd tensor and frequencies in .npz format** and the\n**mean PSD in .npy format** stored in the workflow directory defined by\n`base_dir`\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The power pipeline in the **source space** is implemented by the\n  function :func:`ephypype.pipelines.power.create_pipeline_power_src_space`\n  and its Node :class:`ephypype.interfaces.mne.power.Power` compute the PSD\n  by the welch function of the scipy package.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ephypype.gather import get_results  # noqa\nfrom visbrain.objects import SourceObj, SceneObj, ColorbarObj  # noqa\nfrom visbrain.utils import normalize  # noqa\nfrom nipype.utils.filemanip import split_filename  # noqa\n\npsd_files, channel_coo_files = get_results(main_workflow.base_dir,\n                                           main_workflow.name,\n                                           pipeline='power')\n\nsc = SceneObj(size=(1800, 500), bgcolor=(.1, .1, .1))\nfor psd_file, channel_coo_file in zip(psd_files, channel_coo_files):\n    path_xyz, basename, ext = split_filename(psd_file)\n\n    arch = np.load(psd_file)\n    psds, freqs = arch['psds'], arch['freqs']\n    xyz = np.genfromtxt(channel_coo_file, dtype=float)\n    freq_bands = np.asarray(freq_bands)\n    clim = (psds.min(), psds.max())\n    cmap = 'cool'\n    txtcolor = 'white'\n\n    # Find indices of frequencies :\n    idx_fplt = np.abs((freqs.reshape(1, 1, -1) -\n                       freq_bands[..., np.newaxis])).argmin(2)\n    psdf = np.array([psds[:, k[0]:k[1]].mean(1) for k in idx_fplt])\n    radius = normalize(np.c_[psdf.min(1), psdf.max(1)], 5, 25).astype(float)\n\n    for num, (fb, fbn, psd, rx) in enumerate(zip(freq_bands, freq_band_names,\n                                                 psdf, radius)):\n        s_obj = SourceObj('s', xyz, data=psd, radius_min=rx[0], radius_max=rx[1])  # noqa\n        s_obj.color_sources(data=psd, cmap=cmap, clim=clim)\n        sc.add_to_subplot(s_obj, col=num, title=str(fb) + ' - ' + fbn,\n                          title_color=txtcolor, rotate='top', zoom=.6)\n    cbar = ColorbarObj(s_obj, txtcolor=txtcolor, cblabel='PSD', txtsz=15,\n                       cbtxtsz=20)\n    sc.add_to_subplot(cbar, col=len(freq_bands), width_max=200)\n\nsc.preview()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}